{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not import fast_util.\n"
     ]
    }
   ],
   "source": [
    "import faro\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = \"http://groups.csail.mit.edu/vision/LabelMe/NewImages/indoorCVPR_09.tar\"\n",
    "\n",
    "DATASET_TAR = os.path.join(faro.DEFAULT_STORAGE_DIR,'train','indoorCVPR_09.tar')\n",
    "\n",
    "DATASET_DIR = os.path.join(faro.DEFAULT_STORAGE_DIR,'train','Images')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(faro.DEFAULT_STORAGE_DIR,'train')):\n",
    "    os.mkdir(os.path.join(faro.DEFAULT_STORAGE_DIR,'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset if it does not exist.\n",
    "if not os.path.exists(DATASET_TAR):\n",
    "    import urllib\n",
    "    opener = urllib.request.URLopener()\n",
    "    print(\"Downloading dataset (2.4GB) to %s.  This may take some time.\"%(DATASET_TAR,))\n",
    "    opener.retrieve(DATASET_URL, DATASET_TAR)\n",
    "    print(\"Download complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the dataset\n",
    "if not os.path.exists(DATASET_DIR):\n",
    "    print(\"Extracting the dataset.\")\n",
    "    ! tar xf $DATASET_TAR\n",
    "    ! mv Images $DATASET_DIR\n",
    "    print(\"Extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport_inside\tcomputerroom\t     inside_subway   pantry\r\n",
      "artstudio\tconcert_hall\t     jewelleryshop   poolinside\r\n",
      "auditorium\tcorridor\t     kindergarden    prisoncell\r\n",
      "bakery\t\tdeli\t\t     kitchen\t     restaurant\r\n",
      "bar\t\tdentaloffice\t     laboratorywet   restaurant_kitchen\r\n",
      "bathroom\tdining_room\t     laundromat      shoeshop\r\n",
      "bedroom\t\televator\t     library\t     stairscase\r\n",
      "bookstore\tfastfood_restaurant  livingroom      studiomusic\r\n",
      "bowling\t\tflorist\t\t     lobby\t     subway\r\n",
      "buffet\t\tgameroom\t     locker_room     toystore\r\n",
      "casino\t\tgarage\t\t     mall\t     trainstation\r\n",
      "children_room\tgreenhouse\t     meeting_room    tv_studio\r\n",
      "church_inside\tgrocerystore\t     movietheater    videostore\r\n",
      "classroom\tgym\t\t     museum\t     waitingroom\r\n",
      "cloister\thairsalon\t     nursery\t     warehouse\r\n",
      "closet\t\thospitalroom\t     office\t     winecellar\r\n",
      "clothingstore\tinside_bus\t     operating_room\r\n"
     ]
    }
   ],
   "source": [
    "!ls $DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15620 images belonging to 67 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                         rotation_range=20,\n",
    "                                                         width_shift_range=0.2,\n",
    "                                                         height_shift_range=0.2,\n",
    "                                                         zoom_range=0.2,\n",
    "                                                        horizontal_flip=True)\n",
    "my_iter = generator.flow_from_directory(DATASET_DIR,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = my_iter.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 256, 256, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Generate dummy data\n",
    "#x_train = np.random.random((100, 100, 100, 3))\n",
    "#y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "#x_test = np.random.random((20, 100, 100, 3))\n",
    "#y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(67, activation='softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "#model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "#score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD,Adam\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "128/128 [==============================] - 345s 3s/step - loss: 4.0463\n",
      "Epoch 2/25\n",
      "128/128 [==============================] - 335s 3s/step - loss: 3.9485\n",
      "Epoch 3/25\n",
      "128/128 [==============================] - 334s 3s/step - loss: 3.9058\n",
      "Epoch 4/25\n",
      "128/128 [==============================] - 334s 3s/step - loss: 3.8259\n",
      "Epoch 5/25\n",
      "128/128 [==============================] - 336s 3s/step - loss: 3.7699\n",
      "Epoch 6/25\n",
      "128/128 [==============================] - 331s 3s/step - loss: 3.7600\n",
      "Epoch 7/25\n",
      "128/128 [==============================] - 335s 3s/step - loss: 3.7405\n",
      "Epoch 8/25\n",
      "128/128 [==============================] - 327s 3s/step - loss: 3.6371\n",
      "Epoch 9/25\n",
      "128/128 [==============================] - 337s 3s/step - loss: 3.6041\n",
      "Epoch 10/25\n",
      "128/128 [==============================] - 329s 3s/step - loss: 3.5258\n",
      "Epoch 11/25\n",
      "128/128 [==============================] - 337s 3s/step - loss: 3.5249\n",
      "Epoch 12/25\n",
      "128/128 [==============================] - 326s 3s/step - loss: 3.4811\n",
      "Epoch 13/25\n",
      "128/128 [==============================] - 340s 3s/step - loss: 3.4589\n",
      "Epoch 14/25\n",
      "128/128 [==============================] - 331s 3s/step - loss: 3.4133\n",
      "Epoch 15/25\n",
      "128/128 [==============================] - 334s 3s/step - loss: 3.3666\n",
      "Epoch 16/25\n",
      "128/128 [==============================] - 325s 3s/step - loss: 3.3616\n",
      "Epoch 17/25\n",
      "128/128 [==============================] - 337s 3s/step - loss: 3.3198\n",
      "Epoch 18/25\n",
      "128/128 [==============================] - 330s 3s/step - loss: 3.3130\n",
      "Epoch 19/25\n",
      "128/128 [==============================] - 335s 3s/step - loss: 3.2835\n",
      "Epoch 20/25\n",
      "128/128 [==============================] - 333s 3s/step - loss: 3.2453\n",
      "Epoch 21/25\n",
      "128/128 [==============================] - 335s 3s/step - loss: 3.2401\n",
      "Epoch 22/25\n",
      "128/128 [==============================] - 337s 3s/step - loss: 3.1972\n",
      "Epoch 23/25\n",
      "128/128 [==============================] - 331s 3s/step - loss: 3.1774\n",
      "Epoch 24/25\n",
      "128/128 [==============================] - 332s 3s/step - loss: 3.1678\n",
      "Epoch 25/25\n",
      "128/128 [==============================] - 333s 3s/step - loss: 3.1382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55803b17f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(my_iter,steps_per_epoch=128,epochs=25,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
