{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faro\n",
    "import faro.proto.proto_types as pt\n",
    "import os\n",
    "import pyvision as pv\n",
    "import cv2\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaroDetectionOptions(object):\n",
    "    #user could change these variable : User-defined variables\n",
    "    def __init__(self):\n",
    "        #root file\n",
    "        self.results_root_path = '/home/nv5/Research/FaceRecognition/faro/Notebooks/results'\n",
    "        self.csvfiles_log = 'csvfiles'\n",
    "        #Directory to save images with bounding boxes\n",
    "        self.detect_log = 'detect_log'\n",
    "        #Directory to save cropped face images (128*128)\n",
    "        self.face_log = 'face_log'\n",
    "        #Set to True if you want to save only the detection with \n",
    "        #the highest detection score (confidence)\n",
    "        self.best = False\n",
    "        #Detection Thresh - Retinaface uses 0.5 in their examples\n",
    "        self.detect_thresh = 0.5\n",
    "        #Set min size. If the bouding box of the face detected is\n",
    "        #less that min_size then it will be discarded.\n",
    "        self.min_size = 0\n",
    "        #Set the maximum number of images it can process\n",
    "        self.max_images = None\n",
    "        self.max_size = None\n",
    "\n",
    "class FaroClientConnectionOptions(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.max_async = faro.DEFAULT_MAX_ASYNC\n",
    "        self.max_message_size = faro.DEFAULT_MAX_MESSAGE_SIZE\n",
    "        self.detect_port = faro.DEFAULT_PORT\n",
    "        self.rec_port = faro.DEFAULT_PORT\n",
    "        self.verbose = True\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method FaceClient.status of <faro.FaceClient.FaceClient object at 0x7fe341f001d0>>\n",
      "<class 'faro.proto.face_service_pb2.FaceServiceInfo'> status: READY\n",
      "detection_support: true\n",
      "extract_support: true\n",
      "score_support: true\n",
      "score_type: NEG_DOT\n",
      "detection_threshold: 0.5\n",
      "match_threshold: -0.42838144302368164\n",
      "algorithm: \"ArcFace-model arcface_r100_v1\"\n",
      "\n",
      "Connection to FaRO service established. [ algorithm: ArcFace-model arcface_r100_v1 ]\n"
     ]
    }
   ],
   "source": [
    "client_options = FaroClientConnectionOptions()\n",
    "face_client = faro.FaceClient(client_options)\n",
    "is_ready,status = face_client.status(verbose=client_options.verbose)\n",
    "if not is_ready:\n",
    "    print(\"ERROR: the FaRO service is not ready.\")\n",
    "    print(status)\n",
    "    exit(-1)\n",
    "else:\n",
    "    if client_options.verbose:\n",
    "        print('Connection to FaRO service established. [ algorithm: %s ]'%(status.algorithm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesToProcess(args):\n",
    "    images = []\n",
    "    videos = []\n",
    "    for each in args:\n",
    "        print(each)\n",
    "        if os.path.isfile(each) and pv.isImage(each):\n",
    "            images.append(each)\n",
    "        elif os.path.isfile(each) and pv.isVideo(each):\n",
    "            videos.append(each)\n",
    "        elif os.path.isdir(each):\n",
    "            for path,dirs,files in os.walk(each):\n",
    "                for filename in files:\n",
    "                    #print(filename)\n",
    "                    filepath = os.path.join(path,filename)\n",
    "                    if os.path.isfile(filepath) and pv.isImage(filepath):\n",
    "                        images.append(filepath)\n",
    "                    if os.path.isfile(filepath) and pv.isVideo(filepath):\n",
    "                        videos.append(filepath)\n",
    "        else :\n",
    "            raise ValueError(\"Cannot determine filetype:\"+each)\n",
    "\n",
    "    print(\"Found %d images and %d videos.\"%(len(images),len(videos)))\n",
    "    return images, videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImage(im_interest, doptions):\n",
    "    scale = 1.0\n",
    "    while max(*im_interest.shape[:2]) > doptions.max_size:\n",
    "        if max(*im_interest.shape[:2]) > 2*doptions.max_size:\n",
    "            im = cv2.pyrDown(im)\n",
    "            scale *= 0.5\n",
    "        else:\n",
    "            w,h = im.shape[:2]\n",
    "            s = doptions.max_size/max(w,h)\n",
    "            scale *= s\n",
    "            w = int(s*w)\n",
    "            h = int(s*h)\n",
    "            im = cv2.resize(im,(w,h))\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tests/data\n",
      "Found 9 images and 1 videos.\n"
     ]
    }
   ],
   "source": [
    "detection_options = FaroDetectionOptions()\n",
    "if not os.path.isdir(detection_options.results_root_path):\n",
    "    os.makedirs(detection_options.results_root_path)\n",
    "#define data path \n",
    "data_dir = ['../tests/data']\n",
    "image_list, video_list = getFilesToProcess(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_detections(each):\n",
    "    im, results, options, media_type = each\n",
    "    if results.done():\n",
    "        recs = results.result().face_records\n",
    "        i = 0\n",
    "        for idx, face in enumerate(recs):\n",
    "            base_name, ext = os.path.splitext(os.path.basename(face.source))\n",
    "            # Filter faces based on min size\n",
    "            size = min(face.detection.location.width,face.detection.location.height)\n",
    "            if size < options.min_size:\n",
    "                continue\n",
    "    \n",
    "            # Process Detections\n",
    "            if idx == 0:\n",
    "                image_detection_file = open(os.path.join(options.results_root_path, \n",
    "                                                         options.csvfiles_log, media_type, base_name + '.csv'), 'w')\n",
    "                file_identifier = csv.writer(image_detection_file)\n",
    "                if len(face.landmarks) > 0:\n",
    "                    file_identifier.writerow(['source','frame','detect_id','type','score','x','y','w','h',\n",
    "                                             'lmark_id_1','lmark_x','lmark_y', 'lmark_id_2','lmark_x',\n",
    "                                             'lmark_y','lmark_id_3','lmark_x','lmark_y','lmark_id_4',\n",
    "                                             'lmark_x','lmark_y','lmark_id_5','lmark_x','lmark_y'])\n",
    "                else:\n",
    "                    file_identifier.writerow(['source','frame','detect_id','type','score','x','y','w','h'])\n",
    "                        \n",
    "                                 \n",
    "                \n",
    "            if len(face.landmarks) > 0:\n",
    "                file_identifier.writerow([face.source,\n",
    "                                        face.frame,\n",
    "                                        i,\n",
    "                                        face.detection.detection_class,\n",
    "                                        face.detection.score,\n",
    "                                        face.detection.location.x,\n",
    "                                        face.detection.location.y,\n",
    "                                        face.detection.location.width,\n",
    "                                        face.detection.location.height,\n",
    "                                        face.landmarks[0].landmark_id,face.landmarks[0].location.x, face.landmarks[0].location.y,\n",
    "                                        face.landmarks[1].landmark_id,face.landmarks[1].location.x, face.landmarks[1].location.y,\n",
    "                                        face.landmarks[2].landmark_id,face.landmarks[2].location.x, face.landmarks[2].location.y,\n",
    "                                        face.landmarks[3].landmark_id,face.landmarks[3].location.x, face.landmarks[3].location.y,\n",
    "                                        face.landmarks[4].landmark_id,face.landmarks[4].location.x, face.landmarks[4].location.y])\n",
    "            else:\n",
    "                file_identifier.writerow([face.source,\n",
    "                                        face.frame,\n",
    "                                        i,\n",
    "                                        face.detection.detection_class,\n",
    "                                        face.detection.score,\n",
    "                                        face.detection.location.x,\n",
    "                                        face.detection.location.y,\n",
    "                                        face.detection.location.width,\n",
    "                                        face.detection.location.height])\n",
    "\n",
    "                \n",
    "            if options.detect_log:\n",
    "                detect_log_dir = os.path.join(options.results_root_path, options.detect_log, media_type)\n",
    "                if not os.path.exists(detect_log_dir):\n",
    "                    os.makedirs(detect_log_dir, exist_ok=True)\n",
    "                rect = pt.rect_proto2pv(face.detection.location)\n",
    "                if idx == 0:\n",
    "                    dimg = pv.Image(im[:,:,::-1])\n",
    "                dimg.annotateThickRect(rect)\n",
    "                dimg.annotateLabel(pv.Point(rect.x+5,rect.y+5),face.detection.detection_class)\n",
    "                dimg.annotateLabel(pv.Point(rect.x+5,rect.y+20),\n",
    "                                    \"Score: %0.4f\"%(face.detection.score,), color='yellow')\n",
    "                if len(face.landmarks) > 0:\n",
    "                    for each_lmark in face.landmarks:\n",
    "                            dimg.annotateCircle(pv.Point(each_lmark.location.x, each_lmark.location.y), \n",
    "                                                radius=3, color = 'green', fill='green')\n",
    "                \n",
    "            \n",
    "            if options.face_log:\n",
    "                face_log_dir = os.path.join(options.results_root_path, options.face_log, media_type)\n",
    "                if not os.path.exists(face_log_dir):\n",
    "                    os.makedirs(face_log_dir, exist_ok=True)\n",
    "                #print(face.detection.location)\n",
    "                \n",
    "                rect = pt.rect_proto2pv(face.detection.location)\n",
    "                rect = rect.rescale(1.5)\n",
    "                affine = pv.AffineFromRect(rect,(128,128))\n",
    "    \n",
    "                try:\n",
    "                    pvim = pv.Image(im[:,:,::-1])\n",
    "                    view = affine(pvim)\n",
    "                    if len(face.landmarks) > 0:\n",
    "                        for each_lmark in face.landmarks:\n",
    "                            transformed_lmarks = affine(pv.Point(each_lmark.location.x, each_lmark.location.y))\n",
    "                            view.annotateCircle(transformed_lmarks, radius=3, color = 'green', fill='green')\n",
    "  \n",
    "                    base_name, ext = os.path.splitext(os.path.basename(face.source))\n",
    "                    out_path = os.path.join(face_log_dir,\n",
    "                                            os.path.basename(base_name)+'_face_%03d'%(face.detection.detection_id,)+ext)\n",
    "                    \n",
    "                    view.asAnnotated().save(out_path)\n",
    "                    print('Saving face:',out_path)\n",
    "                except:\n",
    "                    print(\"WARNING: Image not processed correctly:\",face.source)\n",
    "            i += 1\n",
    "        \n",
    "        if options.detect_log:\n",
    "            dimg.asAnnotated().save(os.path.join(detect_log_dir,\n",
    "                                                     os.path.basename(base_name) + ext))\n",
    "        image_detection_file.close()\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(ilist, doptions):\n",
    "    image_count = 0\n",
    "    detect_queue = []\n",
    "    start_time = time.time()\n",
    "    for each_img in ilist:\n",
    "        im = cv2.imread(each_img)\n",
    "        \n",
    "        if im is None:\n",
    "            continue\n",
    "        # convert BGR to RGB\n",
    "        im = im[:,:,::-1]\n",
    "        if doptions.max_size is not None:\n",
    "            im, scale = preprocessImage(im, doptions)\n",
    "        results = face_client.detect(im, best=doptions.best, \n",
    "                             threshold=doptions.detect_thresh, \n",
    "                             min_size=doptions.min_size,\n",
    "                             run_async=True, \n",
    "                             source=each_img, \n",
    "                             frame=-1)\n",
    "        detect_queue.append([im, results, doptions, 'image'])\n",
    "        detect_queue = list(filter(process_image_detections, detect_queue))\n",
    "        image_count += 1\n",
    "        if doptions.max_images is not None and image_count >= options.max_images:\n",
    "            break \n",
    "            \n",
    "    while len(detect_queue):\n",
    "        detect_queue = list(filter(process_image_detections,detect_queue))\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "        end_time = time.time() - start_time\n",
    "    print(\"Processed %d images in %0.3f seconds: %f images/second\"%(image_count,end_time - start_time,\n",
    "                                                                    image_count/(end_time - start_time)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/image/trump1_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/image/trump2_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/image/trump3_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/image/obama1_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/image/obama2_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/image/obama3_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/image/bush2_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/image/bush3_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/image/children_face_000.jpg\n",
      "Processed 9 images in -1592515241.548 seconds: -0.000000 images/second\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(os.path.join(detection_options.results_root_path, detection_options.csvfiles_log, 'image')):\n",
    "    os.makedirs(os.path.join(detection_options.results_root_path, detection_options.csvfiles_log, 'image'))\n",
    "process_images(image_list, detection_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View one output\n",
    "\n",
    "if detection_options.detect_log is not None:\n",
    "    from glob import glob\n",
    "    bbox_imgs = glob(os.path.join(detection_options.detect_log,'*'))\n",
    "    img = pv.Image(bbox_imgs[8])\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "if detection_options.face_log is not None:\n",
    "    from glob import glob\n",
    "    bbox_imgs = glob(os.path.join(detection_options.face_log,'*'))\n",
    "    print(len(bbox_imgs))\n",
    "    img_path = bbox_imgs[1]\n",
    "\n",
    "img = pv.Image(img_path)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_detections(each):\n",
    "    global video_header_flag\n",
    "    im, results, options, file_identifier, media_type = each\n",
    "    if results.done():\n",
    "        recs = results.result().face_records\n",
    "        i = 0\n",
    "        detect_log_dir = None\n",
    "        frame_id = None\n",
    "        for idx, face in enumerate(recs):\n",
    "            base_name, ext = os.path.splitext(os.path.basename(face.source))\n",
    "            # Filter faces based on min size\n",
    "            size = min(face.detection.location.width,face.detection.location.height)\n",
    "            if size < options.min_size:\n",
    "                continue\n",
    "    \n",
    "            if video_header_flag:\n",
    "                if len(face.landmarks) > 0:\n",
    "                    file_identifier.writerow(['source','frame','detect_id','type','score','x','y','w','h',\n",
    "                                         'lmark_id_1','lmark_x','lmark_y', 'lmark_id_2','lmark_x',\n",
    "                                         'lmark_y','lmark_id_3','lmark_x','lmark_y','lmark_id_4',\n",
    "                                         'lmark_x','lmark_y','lmark_id_5','lmark_x','lmark_y'])\n",
    "                else:\n",
    "                    file_identifier.writerow(['source','frame','detect_id','type','score','x','y','w','h'])\n",
    "                \n",
    "                video_header_flag = False\n",
    "                                    \n",
    "\n",
    "            if len(face.landmarks) > 0:\n",
    "                file_identifier.writerow([face.source,\n",
    "                                        face.frame,\n",
    "                                        i,\n",
    "                                        face.detection.detection_class,\n",
    "                                        face.detection.score,\n",
    "                                        face.detection.location.x,\n",
    "                                        face.detection.location.y,\n",
    "                                        face.detection.location.width,\n",
    "                                        face.detection.location.height,\n",
    "                                        face.landmarks[0].landmark_id,face.landmarks[0].location.x, face.landmarks[0].location.y,\n",
    "                                        face.landmarks[1].landmark_id,face.landmarks[1].location.x, face.landmarks[1].location.y,\n",
    "                                        face.landmarks[2].landmark_id,face.landmarks[2].location.x, face.landmarks[2].location.y,\n",
    "                                        face.landmarks[3].landmark_id,face.landmarks[3].location.x, face.landmarks[3].location.y,\n",
    "                                        face.landmarks[4].landmark_id,face.landmarks[4].location.x, face.landmarks[4].location.y])\n",
    "            else:\n",
    "                file_identifier.writerow([face.source,\n",
    "                                        face.frame,\n",
    "                                        i,\n",
    "                                        face.detection.detection_class,\n",
    "                                        face.detection.score,\n",
    "                                        face.detection.location.x,\n",
    "                                        face.detection.location.y,\n",
    "                                        face.detection.location.width,\n",
    "                                        face.detection.location.height])\n",
    "                \n",
    "            if options.detect_log:\n",
    "                detect_log_dir = os.path.join(options.results_root_path, options.detect_log, media_type, base_name)\n",
    "                frame_id = face.frame\n",
    "                if not os.path.exists(detect_log_dir):\n",
    "                    os.makedirs(detect_log_dir, exist_ok=True)\n",
    "                \n",
    "                rect = pt.rect_proto2pv(face.detection.location)\n",
    "                if idx == 0:\n",
    "                    dimg = pv.Image(im[:,:,::-1])\n",
    "                dimg.annotateThickRect(rect)\n",
    "                dimg.annotateLabel(pv.Point(rect.x+5,rect.y+5),face.detection.detection_class)\n",
    "                dimg.annotateLabel(pv.Point(rect.x+5,rect.y+20),\n",
    "                                    \"Score: %0.4f\"%(face.detection.score,), color='yellow')\n",
    "                if len(face.landmarks) > 0:\n",
    "                    for each_lmark in face.landmarks:\n",
    "                            dimg.annotateCircle(pv.Point(each_lmark.location.x, each_lmark.location.y), \n",
    "                                                radius=3, color = 'green', fill='green')\n",
    "                \n",
    "            \n",
    "            if options.face_log:\n",
    "                face_log_dir = os.path.join(options.results_root_path, options.face_log, media_type, base_name)\n",
    "                if not os.path.exists(face_log_dir):\n",
    "                    os.makedirs(face_log_dir, exist_ok=True)\n",
    "                \n",
    "                rect = pt.rect_proto2pv(face.detection.location)\n",
    "                rect = rect.rescale(1.5)\n",
    "                affine = pv.AffineFromRect(rect,(128,128))\n",
    "                try:    \n",
    "                    pvim = pv.Image(im[:,:,::-1])\n",
    "                    view = affine(pvim)\n",
    "                    out_path = os.path.join(face_log_dir,os.path.basename(base_name)+\n",
    "                                            '_Frame_%06d'%(face.frame) +\n",
    "                                            '_face_%03d'%(face.detection.detection_id,)+ '.jpg')\n",
    "                    if len(face.landmarks) > 0:\n",
    "                        for each_lmark in face.landmarks:\n",
    "                            transformed_lmarks = affine(pv.Point(each_lmark.location.x, each_lmark.location.y))\n",
    "                            view.annotateCircle(transformed_lmarks, radius=3, color = 'green', fill='green')\n",
    "                    view.asAnnotated().save(out_path)\n",
    "                    print('Saving face:',out_path)\n",
    "                except:\n",
    "                    print(\"WARNING: Image not processed correctly:\",face.source)\n",
    "            i += 1\n",
    "        \n",
    "        if options.detect_log and detect_log_dir is not None:\n",
    "            dimg.asAnnotated().save(os.path.join(detect_log_dir,\n",
    "                                                 os.path.basename(base_name) + '_Frame_%06d'%(frame_id) + '.jpg'))\n",
    "        return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos(each_video, doptions):\n",
    "    detect_queue = []\n",
    "    #Read Video\n",
    "    video = pv.Video(each_video)\n",
    "    videoname, ext = os.path.splitext(os.path.basename(each_video))\n",
    "    fid = open(os.path.join(doptions.results_root_path,\n",
    "                            doptions.csvfiles_log, 'video', videoname + '.csv') , 'w')\n",
    "    video_detections_csv = csv.writer(fid)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for frame_id, each_frame in enumerate(video):\n",
    "\n",
    "        each_frame = each_frame.asOpenCV2()[:,:,::-1]#convert to opencv and then bgrtorgb\n",
    "        if doptions.max_size is not None:\n",
    "            each_frame, scale = preprocessImage(each_frame, doptions)\n",
    "        results = face_client.detect(each_frame, best=doptions.best, \n",
    "                             threshold=doptions.detect_thresh, \n",
    "                             min_size=doptions.min_size,\n",
    "                             run_async=True, \n",
    "                             source=each_video, \n",
    "                             frame=frame_id)\n",
    "        detect_queue.append([each_frame, results, doptions, video_detections_csv, 'video'])\n",
    "        detect_queue = list(filter(process_video_detections, detect_queue))\n",
    "\n",
    "        \n",
    "    while len(detect_queue):\n",
    "        detect_queue = list(filter(process_video_detections,detect_queue))\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    \n",
    "        \n",
    "    end_time = time.time() - start_time\n",
    "    print(\"Processed %d frames in %0.3f seconds: %f images/second\"%(frame_id+1,end_time - start_time,\n",
    "                                                                    (frame_id+1)/(end_time - start_time)))\n",
    "    \n",
    "    fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/video/File_ID_1229_Face/File_ID_1229_Face_Frame_000000_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/video/File_ID_1229_Face/File_ID_1229_Face_Frame_000001_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/video/File_ID_1229_Face/File_ID_1229_Face_Frame_000002_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/video/File_ID_1229_Face/File_ID_1229_Face_Frame_000003_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/video/File_ID_1229_Face/File_ID_1229_Face_Frame_000004_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/video/File_ID_1229_Face/File_ID_1229_Face_Frame_000005_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/video/File_ID_1229_Face/File_ID_1229_Face_Frame_000006_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/video/File_ID_1229_Face/File_ID_1229_Face_Frame_000007_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/video/File_ID_1229_Face/File_ID_1229_Face_Frame_000008_face_000.jpg\n",
      "Saving face: /home/nv5/Research/FaceRecognition/faro/Notebooks/results/face_log/video/File_ID_1229_Face/File_ID_1229_Face_Frame_000009_face_000.jpg\n",
      "Processed 3100 frames in -1592515242.002 seconds: -0.000002 images/second\n"
     ]
    }
   ],
   "source": [
    "video_header_flag = None\n",
    "if not os.path.isdir(os.path.join(detection_options.results_root_path, detection_options.csvfiles_log, 'video')):\n",
    "    os.makedirs(os.path.join(detection_options.results_root_path, detection_options.csvfiles_log, 'video'))\n",
    "for each_video in video_list:\n",
    "    global video_header_flag \n",
    "    video_header_flag = True\n",
    "    process_videos(each_video, detection_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read images from detect_log dir and convert it to a video and play it\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
