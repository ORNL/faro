{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faro\n",
    "import faro.proto.proto_types as pt\n",
    "import os\n",
    "import pyvision as pv\n",
    "import cv2\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaroDetectionOptions(object):\n",
    "    #user could change these variable : User-defined variables\n",
    "    def __init__(self):\n",
    "        #root file\n",
    "        self.results_root_path = '/home/nv5/Research/FaceRecognition/faro/Notebooks/results'\n",
    "        self.csvfiles_log = 'csvfiles_log'\n",
    "        #Directory to save images with bounding boxes\n",
    "        self.detect_log = 'detect_log'\n",
    "        #Directory to save cropped face images (128*128)\n",
    "        self.face_log = 'face_log'\n",
    "        #Set to True if you want to save only the detection with \n",
    "        #the highest detection score (confidence)\n",
    "        self.best = False\n",
    "        #Detection Thresh - Retinaface uses 0.5 in their examples\n",
    "        self.detect_thresh = 0.5\n",
    "        #Set min size. If the bouding box of the face detected is\n",
    "        #less that min_size then it will be discarded.\n",
    "        self.min_size = 0\n",
    "        #Set the maximum number of images it can process\n",
    "        self.max_images = None\n",
    "        self.max_size = None\n",
    "\n",
    "class FaroClientConnectionOptions(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.max_async = faro.DEFAULT_MAX_ASYNC\n",
    "        self.max_message_size = faro.DEFAULT_MAX_MESSAGE_SIZE\n",
    "        self.detect_port = faro.DEFAULT_PORT\n",
    "        self.rec_port = faro.DEFAULT_PORT\n",
    "        self.verbose = True\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method FaceClient.status of <faro.FaceClient.FaceClient object at 0x7fd09b79f358>>\n",
      "<class 'faro.proto.face_service_pb2.FaceServiceInfo'> status: READY\n",
      "detection_support: true\n",
      "extract_support: true\n",
      "score_support: true\n",
      "score_type: NEG_DOT\n",
      "detection_threshold: 0.5\n",
      "match_threshold: -0.42838144302368164\n",
      "algorithm: \"ArcFace-model arcface_r100_v1\"\n",
      "\n",
      "Connection to FaRO service established. [ algorithm: ArcFace-model arcface_r100_v1 ]\n"
     ]
    }
   ],
   "source": [
    "client_options = FaroClientConnectionOptions()\n",
    "face_client = faro.FaceClient(client_options)\n",
    "is_ready,status = face_client.status(verbose=client_options.verbose)\n",
    "if not is_ready:\n",
    "    print(\"ERROR: the FaRO service is not ready.\")\n",
    "    print(status)\n",
    "    exit(-1)\n",
    "else:\n",
    "    if client_options.verbose:\n",
    "        print('Connection to FaRO service established. [ algorithm: %s ]'%(status.algorithm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesToProcess(args):\n",
    "    images = []\n",
    "    videos = []\n",
    "    for each in args:\n",
    "        print(each)\n",
    "        if os.path.isfile(each) and pv.isImage(each):\n",
    "            images.append(each)\n",
    "        elif os.path.isfile(each) and pv.isVideo(each):\n",
    "            videos.append(each)\n",
    "        elif os.path.isdir(each):\n",
    "            for path,dirs,files in os.walk(each):\n",
    "                for filename in files:\n",
    "                    #print(filename)\n",
    "                    filepath = os.path.join(path,filename)\n",
    "                    if os.path.isfile(filepath) and pv.isImage(filepath):\n",
    "                        images.append(filepath)\n",
    "                    if os.path.isfile(filepath) and pv.isVideo(filepath):\n",
    "                        videos.append(filepath)\n",
    "        else :\n",
    "            raise ValueError(\"Cannot determine filetype:\"+each)\n",
    "\n",
    "    print(\"Found %d images and %d videos.\"%(len(images),len(videos)))\n",
    "    return images, videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImage(im_interest, doptions):\n",
    "    scale = 1.0\n",
    "    while max(*im_interest.shape[:2]) > doptions.max_size:\n",
    "        if max(*im_interest.shape[:2]) > 2*doptions.max_size:\n",
    "            im = cv2.pyrDown(im)\n",
    "            scale *= 0.5\n",
    "        else:\n",
    "            w,h = im.shape[:2]\n",
    "            s = doptions.max_size/max(w,h)\n",
    "            scale *= s\n",
    "            w = int(s*w)\n",
    "            h = int(s*h)\n",
    "            im = cv2.resize(im,(w,h))\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nv5/Research/FHWA/data/ORNLFHW_DASLowQualityDifficult\n",
      "Found 0 images and 11 videos.\n"
     ]
    }
   ],
   "source": [
    "detection_options = FaroDetectionOptions()\n",
    "if not os.path.isdir(detection_options.results_root_path):\n",
    "    os.makedirs(detection_options.results_root_path)\n",
    "#define data path \n",
    "data_dir = ['/home/nv5/Research/FHWA/data/ORNLFHW_DASLowQualityDifficult']\n",
    "#data_dir = ['/home/nv5/Research/FaceRecognition/faro/tests/data/']\n",
    "image_list, video_list = getFilesToProcess(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_detections(each):\n",
    "    im, results, options, media_type = each\n",
    "    if results.done():\n",
    "        recs = results.result().face_records\n",
    "        i = 0\n",
    "        dimg = None\n",
    "        csv_file = None\n",
    "        for idx, face in enumerate(recs):\n",
    "            base_name, ext = os.path.splitext(os.path.basename(face.source))\n",
    "            # Filter faces based on min size\n",
    "            size = min(face.detection.location.width,face.detection.location.height)\n",
    "            if size < options.min_size:\n",
    "                continue\n",
    "    \n",
    "            # Process Detections\n",
    "            if csv_file is None:\n",
    "                image_detection_file = open(os.path.join(options.results_root_path, \n",
    "                                                         options.csvfiles_log, media_type, base_name + '.csv'), 'w')\n",
    "                file_identifier = csv.writer(image_detection_file)\n",
    "                \n",
    "                csv_header = ['source','frame','detect_id','type','score','x','y','w','h']\n",
    "                if len(face.landmarks) > 0:\n",
    "                    \n",
    "                    for each_lpt in face.landmarks:\n",
    "                        pt_id_label = each_lpt.landmark_id\n",
    "                        xpt_label = pt_id_label + '_x'\n",
    "                        ypt_label = pt_id_label + '_y'\n",
    "                        csv_header.append(pt_id_label)\n",
    "                        csv_header.append(xpt_label)\n",
    "                        csv_header.append(ypt_label)\n",
    "                    \n",
    "                file_identifier.writerow(csv_header)\n",
    "                csv_file = -1\n",
    "                        \n",
    "                                 \n",
    "            csv_eachline = [face.source,\n",
    "                            face.frame,\n",
    "                            i,\n",
    "                            face.detection.detection_class,\n",
    "                            face.detection.score,\n",
    "                            face.detection.location.x,\n",
    "                            face.detection.location.y,\n",
    "                            face.detection.location.width,\n",
    "                            face.detection.location.height]\n",
    "            \n",
    "            if len(face.landmarks) > 0:\n",
    "                for each_lpt in face.landmarks:\n",
    "                    pt_id_label = each_lpt.landmark_id\n",
    "                    xpt_label = each_lpt.location.x\n",
    "                    ypt_label = each_lpt.location.y\n",
    "                    csv_eachline.append(pt_id_label)\n",
    "                    csv_eachline.append(xpt_label)\n",
    "                    csv_eachline.append(ypt_label)\n",
    "                    \n",
    "            file_identifier.writerow(csv_eachline)\n",
    "            \n",
    "                \n",
    "            if options.detect_log:\n",
    "                detect_log_dir = os.path.join(options.results_root_path, options.detect_log, media_type)\n",
    "                if not os.path.exists(detect_log_dir):\n",
    "                    os.makedirs(detect_log_dir, exist_ok=True)\n",
    "                rect = pt.rect_proto2pv(face.detection.location)\n",
    "                if dimg is None:\n",
    "                    dimg = pv.Image(im[:,:,::-1])\n",
    "                dimg.annotateThickRect(rect)\n",
    "                dimg.annotateLabel(pv.Point(rect.x+5,rect.y+5),face.detection.detection_class)\n",
    "                dimg.annotateLabel(pv.Point(rect.x+5,rect.y+20),\n",
    "                                    \"Score: %0.4f\"%(face.detection.score,), color='yellow')\n",
    "                if len(face.landmarks) > 0:\n",
    "                    for each_lmark in face.landmarks:\n",
    "                            dimg.annotateCircle(pv.Point(each_lmark.location.x, each_lmark.location.y), \n",
    "                                                radius=3, color = 'green', fill='green')\n",
    "                \n",
    "            \n",
    "            if options.face_log:\n",
    "                face_log_dir = os.path.join(options.results_root_path, options.face_log, media_type)\n",
    "                if not os.path.exists(face_log_dir):\n",
    "                    os.makedirs(face_log_dir, exist_ok=True)\n",
    "                #print(face.detection.location)\n",
    "                \n",
    "                rect = pt.rect_proto2pv(face.detection.location)\n",
    "                rect = rect.rescale(1.5)\n",
    "                affine = pv.AffineFromRect(rect,(128,128))\n",
    "    \n",
    "                try:\n",
    "                    pvim = pv.Image(im[:,:,::-1])\n",
    "                    view = affine(pvim)\n",
    "                    if len(face.landmarks) > 0:\n",
    "                        for each_lmark in face.landmarks:\n",
    "                            transformed_lmarks = affine(pv.Point(each_lmark.location.x, each_lmark.location.y))\n",
    "                            view.annotateCircle(transformed_lmarks, radius=3, color = 'green', fill='green')\n",
    "  \n",
    "                    base_name, ext = os.path.splitext(os.path.basename(face.source))\n",
    "                    out_path = os.path.join(face_log_dir,\n",
    "                                            os.path.basename(base_name)+'_face_%03d'%(face.detection.detection_id,)+ext)\n",
    "                    \n",
    "                    view.asAnnotated().save(out_path)\n",
    "                    print('Saving face:',out_path)\n",
    "                except:\n",
    "                    print(\"WARNING: Image not processed correctly:\",face.source)\n",
    "            i += 1\n",
    "        \n",
    "        if options.detect_log:\n",
    "            dimg.asAnnotated().save(os.path.join(detect_log_dir,\n",
    "                                                     os.path.basename(base_name) + ext))\n",
    "        image_detection_file.close()\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(ilist, doptions):\n",
    "    image_count = 0\n",
    "    detect_queue = []\n",
    "    start_time = time.time()\n",
    "    for each_img in ilist:\n",
    "        im = cv2.imread(each_img)\n",
    "        \n",
    "        if im is None:\n",
    "            continue\n",
    "        # convert BGR to RGB\n",
    "        im = im[:,:,::-1]\n",
    "        if doptions.max_size is not None:\n",
    "            im = preprocessImage(im, doptions)\n",
    "        results = face_client.detect(im, best=doptions.best, \n",
    "                             threshold=doptions.detect_thresh, \n",
    "                             min_size=doptions.min_size,\n",
    "                             run_async=True, \n",
    "                             source=each_img, \n",
    "                             frame=-1)\n",
    "        detect_queue.append([im, results, doptions, 'image'])\n",
    "        detect_queue = list(filter(process_image_detections, detect_queue))\n",
    "        image_count += 1\n",
    "        if doptions.max_images is not None and image_count >= options.max_images:\n",
    "            break \n",
    "            \n",
    "    while len(detect_queue):\n",
    "        detect_queue = list(filter(process_image_detections,detect_queue))\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print(\"Processed %d images in %0.3f seconds: %f images/second\"%(image_count,end_time - start_time,\n",
    "                                                                    image_count/(end_time - start_time)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 images in 0.000 seconds: 0.000000 images/second\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(os.path.join(detection_options.results_root_path, detection_options.csvfiles_log, 'image')):\n",
    "    os.makedirs(os.path.join(detection_options.results_root_path, detection_options.csvfiles_log, 'image'))\n",
    "process_images(image_list, detection_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #View one output\n",
    "\n",
    "# if detection_options.detect_log is not None:\n",
    "#     from glob import glob\n",
    "#     idir = os.path.join(detection_options.results_root_path, detection_options.detect_log, 'image')\n",
    "#     bbox_imgs = glob(os.path.join(idir,'*'))\n",
    "#     img_path = None\n",
    "#     if len(bbox_imgs) != 0:\n",
    "#         img_path = bbox_imgs[1]\n",
    "        \n",
    "# img = pv.Image(img_path)\n",
    "# img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if detection_options.face_log is not None:\n",
    "#     from glob import glob\n",
    "#     bbox_imgs =  glob(os.path.join(detection_options.results_root_path, detection_options.face_log, 'image','*'))\n",
    "#     img_path = None\n",
    "#     if len(bbox_imgs) != 0:\n",
    "#         img_path = bbox_imgs[1]\n",
    "\n",
    "# img = pv.Image(img_path)\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_detections(each):\n",
    "    global video_header_flag\n",
    "    im, results, options, file_identifier, media_type = each\n",
    "    if results.done():\n",
    "        recs = results.result().face_records\n",
    "        i = 0\n",
    "        detect_log_dir = None\n",
    "        frame_id = None\n",
    "        dimg = None\n",
    "        for idx, face in enumerate(recs):\n",
    "            base_name, ext = os.path.splitext(os.path.basename(face.source))\n",
    "            # Filter faces based on min size\n",
    "            size = min(face.detection.location.width,face.detection.location.height)\n",
    "            if size < options.min_size:\n",
    "                continue\n",
    "    \n",
    "            if video_header_flag:\n",
    "                csv_header = ['source','frame','detect_id','type','score','x','y','w','h']\n",
    "                if len(face.landmarks) > 0:\n",
    "                    for each_lpt in face.landmarks:\n",
    "                        pt_id_label = each_lpt.landmark_id\n",
    "                        xpt_label = pt_id_label + '_x'\n",
    "                        ypt_label = pt_id_label + '_y'\n",
    "                        csv_header.append(pt_id_label)\n",
    "                        csv_header.append(xpt_label)\n",
    "                        csv_header.append(ypt_label)\n",
    "                file_identifier.writerow(csv_header)\n",
    "                video_header_flag = False\n",
    "            \n",
    "            csv_eachline = [face.source,\n",
    "                            face.frame,\n",
    "                            i,\n",
    "                            face.detection.detection_class,\n",
    "                            face.detection.score,\n",
    "                            face.detection.location.x,\n",
    "                            face.detection.location.y,\n",
    "                            face.detection.location.width,\n",
    "                            face.detection.location.height]\n",
    "\n",
    "            if len(face.landmarks) > 0:\n",
    "                for each_lpt in face.landmarks:\n",
    "                    pt_id_label = each_lpt.landmark_id\n",
    "                    xpt_label = each_lpt.location.x\n",
    "                    ypt_label = each_lpt.location.y\n",
    "                    csv_eachline.append(pt_id_label)\n",
    "                    csv_eachline.append(xpt_label)\n",
    "                    csv_eachline.append(ypt_label)\n",
    "                    \n",
    "            file_identifier.writerow(csv_eachline)\n",
    "                \n",
    "            if options.detect_log:\n",
    "                detect_log_dir = os.path.join(options.results_root_path, options.detect_log, media_type, base_name)\n",
    "                frame_id = face.frame\n",
    "                if not os.path.exists(detect_log_dir):\n",
    "                    os.makedirs(detect_log_dir, exist_ok=True)\n",
    "                \n",
    "                rect = pt.rect_proto2pv(face.detection.location)\n",
    "                if dimg is None:\n",
    "                    dimg = pv.Image(im[:,:,::-1])\n",
    "                dimg.annotateThickRect(rect)\n",
    "                dimg.annotateLabel(pv.Point(rect.x+5,rect.y+5),face.detection.detection_class)\n",
    "                dimg.annotateLabel(pv.Point(rect.x+5,rect.y+20),\n",
    "                                    \"Score: %0.4f\"%(face.detection.score,), color='yellow')\n",
    "                if len(face.landmarks) > 0:\n",
    "                    for each_lmark in face.landmarks:\n",
    "                            dimg.annotateCircle(pv.Point(each_lmark.location.x, each_lmark.location.y), \n",
    "                                                radius=3, color = 'green', fill='green')\n",
    "                \n",
    "            \n",
    "            if options.face_log:\n",
    "                face_log_dir = os.path.join(options.results_root_path, options.face_log, media_type, base_name)\n",
    "                if not os.path.exists(face_log_dir):\n",
    "                    os.makedirs(face_log_dir, exist_ok=True)\n",
    "                \n",
    "                rect = pt.rect_proto2pv(face.detection.location)\n",
    "                rect = rect.rescale(1.5)\n",
    "                affine = pv.AffineFromRect(rect,(128,128))\n",
    "                try:    \n",
    "                    pvim = pv.Image(im[:,:,::-1])\n",
    "                    view = affine(pvim)\n",
    "                    out_path = os.path.join(face_log_dir,os.path.basename(base_name)+\n",
    "                                            '_Frame_%06d'%(face.frame) +\n",
    "                                            '_face_%03d'%(face.detection.detection_id,)+ '.jpg')\n",
    "                    if len(face.landmarks) > 0:\n",
    "                        for each_lmark in face.landmarks:\n",
    "                            transformed_lmarks = affine(pv.Point(each_lmark.location.x, each_lmark.location.y))\n",
    "                            view.annotateCircle(transformed_lmarks, radius=3, color = 'green', fill='green')\n",
    "                    view.asAnnotated().save(out_path)\n",
    "                    #print('Saving face:',out_path)\n",
    "                except:\n",
    "                    print(\"WARNING: Image not processed correctly:\",face.source)\n",
    "            i += 1\n",
    "        \n",
    "        if options.detect_log and detect_log_dir is not None:\n",
    "            dimg.asAnnotated().save(os.path.join(detect_log_dir,\n",
    "                                                 os.path.basename(base_name) + '_Frame_%06d'%(frame_id) + '.jpg'))\n",
    "        return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos(each_video, doptions):\n",
    "    detect_queue = []\n",
    "    #Read Video\n",
    "    video = pv.Video(each_video)\n",
    "    videoname, ext = os.path.splitext(os.path.basename(each_video))\n",
    "    fid = open(os.path.join(doptions.results_root_path,\n",
    "                            doptions.csvfiles_log, 'video', videoname + '.csv') , 'w')\n",
    "    video_detections_csv = csv.writer(fid)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for frame_id, each_frame in enumerate(video):\n",
    "\n",
    "        each_frame = each_frame.asOpenCV2()[:,:,::-1]#convert to opencv and then bgrtorgb\n",
    "        if doptions.max_size is not None:\n",
    "            each_frame = preprocessImage(each_frame, doptions)\n",
    "        results = face_client.detect(each_frame, best=doptions.best, \n",
    "                             threshold=doptions.detect_thresh, \n",
    "                             min_size=doptions.min_size,\n",
    "                             run_async=True, \n",
    "                             source=each_video, \n",
    "                             frame=frame_id)\n",
    "        detect_queue.append([each_frame, results, doptions, video_detections_csv, 'video'])\n",
    "        detect_queue = list(filter(process_video_detections, detect_queue))\n",
    "\n",
    "        \n",
    "    while len(detect_queue):\n",
    "        detect_queue = list(filter(process_video_detections,detect_queue))\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    \n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(start_time, end_time, end_time - start_time)\n",
    "    print(\"Processed %d frames in %0.3f seconds: %f images/second\"%(frame_id+1,end_time - start_time,\n",
    "                                                                    (frame_id+1)/(end_time - start_time)))\n",
    "    \n",
    "    fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592581472.0218005 1592581473.1214364 1.0996358394622803\n",
      "Processed 62 frames in 1.100 seconds: 56.382302 images/second\n",
      "1592581473.125851 1592581476.4753425 3.349491596221924\n",
      "Processed 212 frames in 3.349 seconds: 63.293188 images/second\n",
      "1592581476.4813943 1592581477.4741204 0.9927260875701904\n",
      "Processed 47 frames in 0.993 seconds: 47.344379 images/second\n",
      "1592581477.4792001 1592581481.4774776 3.998277425765991\n",
      "Processed 287 frames in 3.998 seconds: 71.780912 images/second\n",
      "1592581481.483788 1592581482.7356837 1.2518956661224365\n",
      "Processed 77 frames in 1.252 seconds: 61.506723 images/second\n",
      "1592581482.7390814 1592581483.4708948 0.7318134307861328\n",
      "Processed 47 frames in 0.732 seconds: 64.224019 images/second\n",
      "1592581483.4755228 1592581486.1864264 2.7109036445617676\n",
      "Processed 182 frames in 2.711 seconds: 67.136285 images/second\n",
      "1592581486.1935828 1592581487.1095922 0.9160094261169434\n",
      "Processed 47 frames in 0.916 seconds: 51.309516 images/second\n",
      "1592581487.1168165 1592581488.6040998 1.4872832298278809\n",
      "Processed 92 frames in 1.487 seconds: 61.857754 images/second\n",
      "1592581488.6085649 1592581490.0103977 1.4018328189849854\n",
      "Processed 91 frames in 1.402 seconds: 64.915016 images/second\n",
      "1592581490.013918 1592581491.3007712 1.286853313446045\n",
      "Processed 77 frames in 1.287 seconds: 59.835880 images/second\n"
     ]
    }
   ],
   "source": [
    "video_header_flag = None\n",
    "if not os.path.isdir(os.path.join(detection_options.results_root_path, detection_options.csvfiles_log, 'video')):\n",
    "    os.makedirs(os.path.join(detection_options.results_root_path, detection_options.csvfiles_log, 'video'))\n",
    "for vid_num, each_video in enumerate(video_list):\n",
    "    global video_header_flag \n",
    "    video_header_flag = True\n",
    "    process_videos(each_video, detection_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read images from detect_log dir and convert it to a video and play it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
